#!/usr/bin/env bash
set -eu

error() { echo >&2 "$@"; false; }

jarFile=$({ cat args-jar || ls target/giraph-debugger-*.jar | head -n 1; } 2>/dev/null)

# use ./giraph-debug in place of hadoop jar when using graft
case $debugConfig in
    none)
        cmd=(
        hadoop jar
        )
        ;;
    *)
        cmd=(
        ./giraph-debug
        $(cat args-giraph-debug 2>/dev/null || true)
        )
esac

# make sure input and output is possible
inputPath=graphs/$graph
outputPath=outputs/$algo/$graph/$_3X_RUN/
outputPathParent=$(dirname "$outputPath")
hadoop fs -test -e $inputPath ||
    error "$inputPath: Graph not found on HDFS"
hadoop fs -test -e $outputPathParent ||
    hadoop fs -mkdir $outputPathParent

# clean up HDFS so it doesn't affect this run's runtime
(set -x; hadoop fs -rmr giraph-debug-traces outputs || true)

# Java VM options for each worker
jvmOpts=(
-Xmx${workerMem:=1g}
-XX:+UseParallelGC
-XX:+PrintGC
-XX:+PrintGCTimeStamps
-XX:+PrintGCDetails
)

# construct list of command-line arguments for GiraphRunner
giraphRunnerArgs=(
$(cat args-algo)
"$@"

-vip $inputPath
-vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat
-op $outputPath

-w ${numWorkers:-1}

# some Giraph/Hadoop configurations to make the runs smoother
-ca mapred.map.child.java.opts="${jvmOpts[*]}"
#-ca mapreduce.job.counters.limit=100000
-ca giraph.useSuperstepCounters=false
)

# make sure the job we launch below is killed when interrupted
cleanup() {
    jobid=$(set +x; grep <../stderr "[m]apred.JobClient: Running job: job_.*" | sed 's/.* Running job: //')
    [ -z "$jobid" ] || hadoop job -kill $jobid
    exit 255
}
trap cleanup INT QUIT TERM

# make sure no jobs are running before launching a new one
hadoop job -list | grep '^job_' | awk '{print $1}' | xargs -L1 --no-run-if-empty --verbose hadoop job -kill

# clean up dangling VMs on all slaves before launching a new job
killSlaveJVMs() {
    local signal=${1:-}
    local kills=$(
        NO_VERBOSE=true \
            foreach-hadoop-slaves 'ps x | grep "[j]ava" |
                grep -Ev "[-]Dproc_(datanode|tasktracker)" |
                awk "{print \$1}" |
                xargs --no-run-if-empty --verbose kill '"$signal" 2>&1 || true
        )
    echo "$kills"
    [[ -n "$kills" ]]
}
t=5s
for signal in TERM TERM TERM KILL; do
    killSlaveJVMs -$signal || break
    echo Waiting for $t
    sleep $t
done >&2

# wait until JVM can be created on all slaves
{
echo "Making sure JVM can be created with options: ${jvmOpts[*]}"
while failures=$(foreach-hadoop-slaves 'java -version '"${jvmOpts[*]}"' &>/dev/null || echo Cannot create JVM'); [[ -n "$failures" ]]; do
    echo "$failures"
    sleep 1
    echo Retrying at $(date)
done
} >&2

# launch a job
set -x
"${cmd[@]}" "$jarFile" \
    org.apache.giraph.GiraphRunner "${giraphRunnerArgs[@]}"
